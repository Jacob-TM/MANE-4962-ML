{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"14o9ZfN_KwGFkpKiaUJOuEvvj0wDwyfZ8","timestamp":1743904495095}],"authorship_tag":"ABX9TyNKsrzhkWdNaeY5Bdb5F+4u"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":36,"metadata":{"id":"pfVVWiNdGBHQ","executionInfo":{"status":"ok","timestamp":1744917436004,"user_tz":240,"elapsed":11,"user":{"displayName":"JakeTheDrake","userId":"01107552549446951353"}}},"outputs":[],"source":["from google.colab import drive, sheets\n","from datetime import datetime\n","import pandas as pd\n","import numpy as np\n","import kagglehub\n","import os"]},{"cell_type":"code","source":["def load_stock_data(assets, data_dir):\n","    \"\"\"\n","    Load and concatenate stock CSV files for given assets.\n","    \"\"\"\n","    dfs = []\n","    for asset in assets:\n","        path = os.path.join(data_dir, f\"{asset}.csv\")\n","        df = pd.read_csv(path)\n","        df.columns = df.columns.str.lower()\n","        df['ticker'] = asset\n","        # Parse and normalize dates to date objects\n","        df['date'] = pd.to_datetime(df['date'], format='%m/%d/%Y', errors='coerce', utc=True).dt.date\n","        dfs.append(df)\n","    return pd.concat(dfs, ignore_index=True)\n","\n","\n","def load_kaggle_headlines(kaggle_path, assets):\n","    \"\"\"\n","    Load and filter Kaggle headlines CSV for specified tickers.\n","    \"\"\"\n","    df = pd.read_csv(kaggle_path)\n","    df.columns = df.columns.str.lower()\n","    df = df.rename(columns={'stock': 'ticker'})\n","    df = df.loc[:, ~df.columns.str.contains('^unnamed', case=False)]\n","    df = df.dropna(subset=['date'])\n","    df = df[df['ticker'].isin(assets)]\n","    df['date'] = pd.to_datetime(df['date'], errors='coerce', utc=True).dt.date\n","    return df\n","\n","\n","def load_custom_headlines(path):\n","    \"\"\"\n","    Load and aggregate custom headlines CSV.\n","    \"\"\"\n","    df = pd.read_csv(path)\n","    df.columns = df.columns.str.lower()\n","    df['date'] = pd.to_datetime(df['date'], errors='coerce').dt.date\n","    return (\n","        df.groupby(['date', 'ticker'], as_index=False)\n","          .agg({'title': lambda x: ' '.join(x.dropna().astype(str))})\n","    )\n","\n","\n","def fill_missing_dates(group):\n","    \"\"\"\n","    Reindex daily and ffill numeric, keep first headline per day.\n","    \"\"\"\n","    group = group.set_index('date').asfreq('D')\n","    for col in ['open', 'high', 'low', 'close', 'volume']:\n","        if col in group.columns:\n","            group[col] = group[col].ffill()\n","    group['ticker'] = group['ticker'].ffill()\n","    group['title'] = group['title'].where(~group['title'].duplicated()).fillna('')\n","    return group.reset_index()\n","\n","\n","def load_data(assets, data_dir, kaggle_path, custom_paths=None):\n","    \"\"\"\n","    Load stock data + headlines, optionally merge custom headlines.\n","\n","    Returns a DataFrame with daily stock data and combined 'title' column.\n","    \"\"\"\n","    df_stocks = load_stock_data(assets, data_dir)\n","    df_kaggle = load_kaggle_headlines(kaggle_path, assets)\n","    df = pd.merge(df_stocks, df_kaggle, on=['date', 'ticker'], how='left')\n","    df['title'] = df.get('title', '').fillna('')\n","\n","    if custom_paths:\n","        for path in custom_paths:\n","            df_custom = load_custom_headlines(path)\n","            df = df.merge(df_custom, on=['date', 'ticker'], how='left', suffixes=('', '_c'))\n","            df['title'] = (df['title'] + ' ' + df.get('title_c','').fillna('')).str.strip()\n","            df = df.drop(columns=['title_c'])\n","\n","    # Rename 'close/last' column if present\n","    if 'close/last' in df.columns:\n","        df = df.rename(columns={'close/last': 'close'})\n","\n","    # Clean price columns\n","    for col in ['open', 'high', 'low', 'close']:\n","        if col in df.columns:\n","            df[col] = df[col].astype(str).str.replace(r\"\\$\", '', regex=True).replace('', pd.NA).astype(float)\n","\n","    # Remove duplicates and fill dates\n","    df = df.drop_duplicates(subset=['ticker', 'date'], keep='last')\n","    df_filled = (\n","        df.sort_values(['ticker','date'])\n","          .groupby('ticker', group_keys=False)\n","          .apply(fill_missing_dates)\n","    )\n","    return df_filled.reset_index(drop=True)\n","\n","\n","def add_vix_values(df, vix_path):\n","    \"\"\"\n","    Merge VIX values into an existing DataFrame, handling arbitrary column names.\n","    \"\"\"\n","    df = df.copy()\n","    df['date'] = pd.to_datetime(df['date'])\n","    df_vix = pd.read_csv(vix_path, parse_dates=['date'])\n","    df_vix.columns = [c.lower() for c in df_vix.columns]\n","    cols = list(df_vix.columns)\n","    if 'value' in cols:\n","        val_col = 'value'\n","    elif len(cols) > 1:\n","        val_col = cols[1]\n","    else:\n","        raise ValueError(f\"No VIX value column found in {vix_path}\")\n","    df_vix = df_vix.rename(columns={cols[0]: 'date', val_col: 'vix_val'})\n","    df_vix['date'] = pd.to_datetime(df_vix['date'])\n","    merged = pd.merge(df, df_vix[['date', 'vix_val']], on='date', how='left')\n","    merged['vix_val'] = merged['vix_val'].ffill()\n","    return merged"],"metadata":{"id":"4ucEPCQ1JRXz","executionInfo":{"status":"ok","timestamp":1744917552227,"user_tz":240,"elapsed":51,"user":{"displayName":"JakeTheDrake","userId":"01107552549446951353"}}},"execution_count":43,"outputs":[]},{"cell_type":"code","source":["assets = ['PG','NVDA']\n","data_dir = '/content/drive/MyDrive/ML/final_project/data/raw'\n","news_tuple = ['/content/drive/MyDrive/ML/final_project/data/misc/nvidia_news_filtered.csv']\n","kaggle_path = '/content/drive/MyDrive/ML/final_project/data/misc/analyst_ratings_processed.csv'\n","\n","df_merged = load_data(assets, data_dir, kaggle_path, news_tuple)"],"metadata":{"id":"5icUYhg5WYqv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1744917559136,"user_tz":240,"elapsed":5862,"user":{"displayName":"JakeTheDrake","userId":"01107552549446951353"}},"outputId":"adfcc224-060a-4ea6-d0da-0eb2d88d027d"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-43-cfda8be9b139>:89: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  .apply(fill_missing_dates)\n"]}]},{"cell_type":"markdown","source":["# Validation that data is formatted correctly"],"metadata":{"id":"Y7Go7lOxUpoz"}},{"source":["sheet = sheets.InteractiveSheet(df=df_merged.assign(date=df_merged['date'].astype(str)))"],"cell_type":"code","execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["https://docs.google.com/spreadsheets/d/1VKsCLqLHKJAIa9t7rO6EXjheAZQ7jmsRBQMCL2igC3E/edit#gid=0\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.lib.display.IFrame at 0x7d9040d0f450>"],"text/html":["\n","        <iframe\n","            width=\"100%\"\n","            height=\"600\"\n","            src=\"https://docs.google.com/spreadsheets/d/1VKsCLqLHKJAIa9t7rO6EXjheAZQ7jmsRBQMCL2igC3E/edit?rm=embedded#gid=0\"\n","            frameborder=\"0\"\n","            allowfullscreen\n","            \n","        ></iframe>\n","        "]},"metadata":{}}],"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/","height":639},"id":"1Cz1SjC_EJTF","executionInfo":{"status":"ok","timestamp":1744917581164,"user_tz":240,"elapsed":7173,"user":{"displayName":"JakeTheDrake","userId":"01107552549446951353"}},"outputId":"8088e974-8f66-434c-ca7f-3d7218f0f04f"}},{"cell_type":"markdown","source":["# Export to csv"],"metadata":{"id":"l8QnkezxAnTo"}},{"cell_type":"code","source":["file_path = '/content/drive/MyDrive/ML/final_project/data/processed/df_merged.csv'\n","df_merged.to_csv(file_path, index=False)"],"metadata":{"id":"wWUlf-uXT_qm","executionInfo":{"status":"ok","timestamp":1744917595506,"user_tz":240,"elapsed":122,"user":{"displayName":"JakeTheDrake","userId":"01107552549446951353"}}},"execution_count":47,"outputs":[]},{"cell_type":"markdown","source":["# Optionally add vix values"],"metadata":{"id":"EU2GbbKBAksc"}},{"cell_type":"code","source":["df_merged_vix = add_vix_values(df_merged, '/content/drive/MyDrive/ML/final_project/data/misc/vix_data.csv')"],"metadata":{"id":"23qcO3z1Amyh","executionInfo":{"status":"ok","timestamp":1744917619979,"user_tz":240,"elapsed":84,"user":{"displayName":"JakeTheDrake","userId":"01107552549446951353"}}},"execution_count":48,"outputs":[]},{"cell_type":"code","source":["sheet = sheets.InteractiveSheet(df=df_merged_vix.assign(date=df_merged['date'].astype(str)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":639},"id":"klEkgJ0jBK0o","executionInfo":{"status":"ok","timestamp":1744917629667,"user_tz":240,"elapsed":8557,"user":{"displayName":"JakeTheDrake","userId":"01107552549446951353"}},"outputId":"b32015a6-fadd-43a4-b3bc-847faeb296c8"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["https://docs.google.com/spreadsheets/d/1oqAt9K9rUuw7uw1G4f3dH2t4Lu1AfsSG2tryeuwaT0M/edit#gid=0\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.lib.display.IFrame at 0x7d904a011f50>"],"text/html":["\n","        <iframe\n","            width=\"100%\"\n","            height=\"600\"\n","            src=\"https://docs.google.com/spreadsheets/d/1oqAt9K9rUuw7uw1G4f3dH2t4Lu1AfsSG2tryeuwaT0M/edit?rm=embedded#gid=0\"\n","            frameborder=\"0\"\n","            allowfullscreen\n","            \n","        ></iframe>\n","        "]},"metadata":{}}]},{"cell_type":"markdown","source":["# Export to csv w/ VIX"],"metadata":{"id":"hvkDqwkJAtv3"}},{"cell_type":"code","source":["file_path = '/content/drive/MyDrive/ML/final_project/data/processed/df_merged_vix.csv'\n","df_merged_vix.to_csv(file_path, index=False)"],"metadata":{"id":"rMoNW8poAwcZ","executionInfo":{"status":"ok","timestamp":1744918028438,"user_tz":240,"elapsed":90,"user":{"displayName":"JakeTheDrake","userId":"01107552549446951353"}}},"execution_count":50,"outputs":[]}]}